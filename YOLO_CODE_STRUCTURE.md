# YOLO Detection Model Code Structure

## üìÅ Directory Structure

```
intrusion-suite/detection-service/
‚îú‚îÄ‚îÄ detectsvc/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # üöÄ Main FastAPI app & detection loop
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # ‚öôÔ∏è Configuration settings
‚îÇ   ‚îú‚îÄ‚îÄ registry.py                # üìã Model registry (manages model metadata)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ accel/                     # üéØ ACCELERATOR MODULE (YOLO Inference)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                # Base classes (Detection, AcceleratorRunner)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ onnx_cpu.py            # ‚≠ê YOLO ONNX MODEL RUNNER (Main YOLO code!)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ pipeline/                  # üîÑ Processing Pipeline
‚îÇ       ‚îú‚îÄ‚îÄ capture.py             # Video frame capture
‚îÇ       ‚îú‚îÄ‚îÄ infer_onnx.py          # Inference pipeline wrapper
‚îÇ       ‚îú‚îÄ‚îÄ tracker.py             # Object tracking
‚îÇ       ‚îî‚îÄ‚îÄ zones.py               # Zone checking
```

---

## üéØ **Main YOLO Code Location**

### **Primary File: `detectsvc/accel/onnx_cpu.py`**

This is where the **YOLO model inference happens**. It contains:

1. **Model Loading** (`load()` method):
   - Loads ONNX model using ONNX Runtime
   - Parses input shape (e.g., 640x640 for YOLO)
   - Sets up inference session

2. **Image Preprocessing** (`infer()` method):
   - Resizes image to model input size (640x640)
   - Converts to tensor format (normalized 0-1)
   - Prepares input for ONNX Runtime

3. **YOLO Inference** (`infer()` method):
   - Runs model: `session.run()` ‚Üí Gets raw YOLO output
   - Raw output format: `[num_detections, 6]` or `[num_detections, 85]`

4. **Postprocessing** (`_postprocess()` method):
   - Parses YOLO output format
   - Converts coordinates from model space to original image space
   - Extracts: bounding boxes (x1, y1, x2, y2), confidence, class
   - Creates `Detection` objects

---

## üîÑ **Execution Flow**

```
1. main.py (detection_loop)
   ‚Üì
2. capture.read() ‚Üí Get frame from camera
   ‚Üì
3. inference_pipeline.infer_frame() ‚Üí infer_onnx.py
   ‚Üì
4. runner.infer() ‚Üí onnx_cpu.py (YOLO inference)
   ‚Üì
5. _postprocess() ‚Üí Convert YOLO output to Detection objects
   ‚Üì
6. tracker.update() ‚Üí Track objects across frames
   ‚Üì
7. broadcast_detections() ‚Üí Send to frontend via WebSocket
```

---

## üìù **Key Code Sections**

### **1. Model Loading** (`onnx_cpu.py` lines 19-89)
```python
def load(self, model_path: Path):
    # Load ONNX model
    self.session = ort.InferenceSession(str(model_path), providers=['CPUExecutionProvider'])
    # Parse input shape (640x640 for YOLO)
    # Set up input/output names
```

### **2. YOLO Inference** (`onnx_cpu.py` lines 91-117)
```python
def infer(self, image: np.ndarray) -> List[Detection]:
    # Preprocess: resize to 640x640, normalize
    resized = cv2.resize(image, (w, h))
    input_tensor = resized.transpose(2, 0, 1).astype(np.float32) / 255.0
    
    # Run YOLO model
    outputs = self.session.run(self.output_names, {self.input_name: input_tensor})
    
    # Postprocess YOLO output
    detections = self._postprocess(outputs[0], image.shape[:2])
    return detections
```

### **3. YOLO Postprocessing** (`onnx_cpu.py` lines 119-220)
```python
def _postprocess(self, output: np.ndarray, orig_shape: Tuple[int, int]):
    # Parse YOLO output format:
    # Format 1: [num_detections, 6] ‚Üí (x1, y1, x2, y2, conf, cls)
    # Format 2: [num_detections, 85] ‚Üí (x, y, w, h, conf, class_probs...)
    
    # Scale bounding boxes from model size (640x640) to original image size
    # Extract class names, confidence scores
    # Create Detection objects
```

---

## üé® **YOLO Output Formats Supported**

### **Format 1: YOLO v11/v8** (lines 142-169)
```python
# Output: [num_detections, 6]
# Columns: [x1, y1, x2, y2, confidence, class_index]
```

### **Format 2: YOLO v5/v8 (older)** (lines 170-220)
```python
# Output: [num_detections, 85]
# Columns: [x_center, y_center, width, height, objectness, class_probs...]
# Converts center+size to x1,y1,x2,y2 format
```

---

## üîó **How It All Connects**

1. **main.py** ‚Üí Starts detection loop, manages state
2. **infer_onnx.py** ‚Üí Wraps multiple models, applies filtering
3. **onnx_cpu.py** ‚Üí **THE YOLO CODE** - actual model inference
4. **tracker.py** ‚Üí Tracks objects across frames
5. **zones.py** ‚Üí Checks if detections are in zones

---

## üìç **Quick Reference**

| Component | File | Purpose |
|-----------|------|---------|
| **YOLO Model Loading** | `accel/onnx_cpu.py:19-89` | Load ONNX model |
| **YOLO Inference** | `accel/onnx_cpu.py:91-117` | Run model on frame |
| **YOLO Postprocessing** | `accel/onnx_cpu.py:119-220` | Parse YOLO output |
| **Detection Loop** | `main.py:221-310` | Main processing loop |
| **Model Management** | `pipeline/infer_onnx.py` | Manage multiple models |

---

## üí° **To Modify YOLO Behavior**

- **Change preprocessing**: Edit `onnx_cpu.py:107-110`
- **Change postprocessing**: Edit `onnx_cpu.py:119-220`
- **Change input size**: Model uses its native size (usually 640x640)
- **Add NMS**: Currently no NMS - model output is used as-is
- **Change confidence filtering**: Edit `infer_onnx.py:78` (user configurable)

---

## üéØ **Summary**

**The main YOLO code is in:**
- **`intrusion-suite/detection-service/detectsvc/accel/onnx_cpu.py`**

This file handles:
- ‚úÖ Loading YOLO ONNX models
- ‚úÖ Preprocessing images for YOLO
- ‚úÖ Running YOLO inference
- ‚úÖ Postprocessing YOLO output to bounding boxes

The rest of the codebase manages the pipeline, tracking, and UI integration.

